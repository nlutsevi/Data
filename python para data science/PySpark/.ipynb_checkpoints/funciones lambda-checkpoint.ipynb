{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc6f1e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"Mi programa\")\n",
    "sc = SparkContext(conf = conf)\n",
    "lines = sc.textFile(\"wiki.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d868c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0fb970d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = lines.filter(lambda line:\"Spark\" in line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e772bd92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ee8dc34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apache Spark és una plataforma de codi obert orientat',\n",
       " \"L'arquitectura d'Apache Spark està basada en el concepte de RDD (Resilient Distributed Dataset), un conjunt de dades immutable distribuït al voltant d'un clúster.[4] Sobre aquesta idea fonamental, es van anar creant capes d'abstracció per a facilitar les tasques de programació i control, utilitzant per exemple el concepte de dataset (joc de dades). Així doncs, com a API es recomana la interfície orientada a datasets des de la versió Spark 2.x[5] malgrat que la orientada a RDD segueix existint.[6][7]\",\n",
       " \"casos ideals per a treballar amb Spark: l'anàlisi exploratori d'un conjunt de \"]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6d64759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Universitat de Califòrnia a Berkeley el 2009, el codi ',\n",
       " \"font fou cedit el 2013 a l'Apache Software Foundation, \",\n",
       " 'qui el manté des de llavors.[1][2][3]',\n",
       " \"L'arquitectura d'Apache Spark està basada en el concepte de RDD (Resilient Distributed Dataset), un conjunt de dades immutable distribuït al voltant d'un clúster.[4] Sobre aquesta idea fonamental, es van anar creant capes d'abstracció per a facilitar les tasques de programació i control, utilitzant per exemple el concepte de dataset (joc de dades). Així doncs, com a API es recomana la interfície orientada a datasets des de la versió Spark 2.x[5] malgrat que la orientada a RDD segueix existint.[6][7]\",\n",
       " \"compartida, la qual cosa n'optimitza l'accés i disponibilitat.[8]\"]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.filter(lambda x: any(i.isdigit() for i in x)).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "acadb506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.filter(lambda x: any(i.isdigit() for i in x)).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8186070f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apache Spark és una plataforma de codi obert orientat',\n",
       " \"a l'analítica i processat de dades massives. Ofereix \",\n",
       " 'una interfície per a treballar amb clústers tot considerant ',\n",
       " 'el paral·lelisme de dades i la tolerància a fallades de ',\n",
       " 'forma implícita. Originàriament desenvolupat per la ']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.filter(lambda x: not any(i.isdigit() for i in x)).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "622bb522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.filter(lambda x: not any(i.isdigit() for i in x)).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80ccd849",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeros = lines.filter(lambda x: any(i.isdigit() for i in x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1dcb1b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[15] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hacer que el objeto sea persistente en memoria\n",
    "numeros.persist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
